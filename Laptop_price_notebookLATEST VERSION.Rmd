---
title: "R Notebook"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---


# DATA MINING PHASE 2 

##### importing needed packages
```{r}
library(stringr)
library(tidyr)
library(data.table)

library(dplyr)

install.packages("outliers")
library(outliers)

install.packages("ggplot2")
library(ggplot2)

library(tidyverse)
library(plotly)
```


##### dataset importing
```{r}
library(readxl)
dataset <- read.csv("C:/Users/Royna/Desktop/Data Mining Project/laptop_price.csv")
View(dataset)
```
## dataset summary : 
##### The dataset includes : 
##### 1- Laptop ID :- Numeric - a unique number identifies laptops 
##### 2- Company : - String - laptop manufacture 
##### 3- Product : - String - brand and model 
##### 4- TypeName : - String - type of the laptop ( notebook,ultrabook,gaming...etc)
##### 5- Inches : - Numeric - screen size 
##### 6- ScreenResulotion : - String - screen resulotion 
##### 7- CPU : - String - central processing unit 
##### 8- Ram : - String - laptop ram 
##### 9- Memory : - String - hard disk / SSD memory 
##### 10- GPu : - String - graphics processing unit 
##### 11- OpSys : - String - operating system 
##### 12- Weight : - String - laptop weight 
##### 13- Price_euros : - Numeric - price in euro



### Raw data set
```{r}
# Display the first 10 rows
head(dataset, 10)

# Display the last 10 rows
tail(dataset, 10)
```
###Graphs helped understanding the dataset 
### Outlier Analysis

#### Detecting outliers

##### We used boxplot graph to indicate the outliers than compared them to the maximum value, we noticed that not all the outlier rows are actually outliers, for example the row with ID 191 is only 3 euros higher from the maximum value, so it was identified as an outlier.
##### We also used z-score method to indicate extreme values from the mean, We compared the two methods and all the z-score results matches the outliers detected in the boxplot. We also went through the rows manually and all z-score results were logical.
```{r}
#-------boxplot --------
#-------outliers--------


bp <- boxplot(dataset$Price_euros)
mean_price <- mean(dataset$Price_euros)
median_values <- bp$stats[3]
lower_quartile <- bp$stats[2]
upper_quartile <- bp$stats[4]
outliers <- bp$out
outliers <- outliers[order(outliers)]


cat("Median:", median_values, "\n")
cat("Lower Quartile (Q1):", lower_quartile, "\n")
cat("Mean Price (euros):", mean_price, "\n")
cat("Upper Quartile (Q3):", upper_quartile, "\n")

# rows with outliers
outlier_indices <- dataset$Price_euros %in% outliers
# only rows with outliers
outliers_data <- dataset[outlier_indices, c("laptop_ID", "Price_euros")]

# analyze price outliers
outliers_data$differenceFromMAx <- outliers_data$Price_euros - 2821

# Calculate standard deviation
sd_price <- sd(dataset$Price_euros)

# z score for outliers
z_scores <- (dataset$Price_euros - mean_price) / sd_price
threshold <- 3



#detecting outliers
outliersInches <- boxplot.stats(dataset$Inches)$out
boxplot(dataset$Inches,
        ylab = "Inches",
        main = "Inches" )


outliersPrice_euros <- boxplot.stats(dataset$Price_euros)$out
boxplot(dataset$Price_euros,
        ylab = "Price_euros",
        main = "Price_euros" )
graphics.off()
x<- dataset
x<- x[-which(dataset$Inches%in% outliersInches),]
x<- x[-which(dataset$Price_euros%in% outliersPrice_euros),]

```


###preprocessing 
###1: nulls

### Missing values
```{r}
#check for missing values
sum(is.na(dataset))

# There are no missing values in our dataset
```
####6:Encoding
##### We replaced the ID attribute in the raw dataset to make sure that the ID indicates each row uniquely.
```{r}
#delete laptop_ID attribute
dataset <- dataset[, -which(names(dataset) == "laptop_ID")]

# making ID coloum
row_numbers <- data.frame(ID = 1:nrow(dataset))
row_numbers$ID <- as.character(row_numbers$ID)
dataset$ID <- row_numbers$ID
dataset <- dataset[, c("ID", names(dataset)[-ncol(dataset)])]
```

```{r}
#unique opsy
unique(dataset$OpSys)
dataset$OpSys=factor(dataset$OpSys,levels=c("macOS","No OS","Windows 10","Mac OS X","Linux","Android","Windows 10 S","Chrome OS","Windows 7"),
                     labels=c("1","2","3","4","5","6","7","8","9"))
```
```{r}

```


###2: converting to numeric

##### We convert Weight attribute from char to numeric by removing the "kg" suffix to apply any needed mathematical operations.
```{r}
#Find unique values in Weight
unique(dataset$Weight)
#sub the kg from Weight attribute
dataset$Weight <- gsub("kg", "", dataset$Weight)
#convert Weight to numeric
dataset$Weight<- as.numeric(as.character(dataset$Weight))


#Find unique values in Ram
unique(dataset$Ram)
#Encode the Ram attribute
dataset$Ram=factor(dataset$Ram,levels=c("8GB","16GB","4GB","2GB","12GB","6GB","32GB","24GB","64GB"),
                   labels=c("8","16","4","2","12","6","32","24","64"))
dataset$Ram<- as.numeric(as.character(dataset$Ram))
dataset$OpSys<- as.numeric(as.character(dataset$OpSys))

```
####3: removing outleirs

##### We used the z-score results to delete the outliers, because it was more logical than the boxplot results.
```{r}
# Create a new dataset containing outliers
deleted_Outliers <- dataset[abs(z_scores) > threshold, ]

#deleting outliers
dataset <- anti_join(dataset, deleted_Outliers, by = "ID")
row_numbers <- data.frame(ID = 1:nrow(dataset))
row_numbers$ID <- as.character(row_numbers$ID)
dataset$ID <- row_numbers$ID

#boxplot after removing outliers
bp <- boxplot(dataset$Price_euros)
# +++++median now is in the middle+++++
mean_price <- mean(dataset$Price_euros)
median_values <- bp$stats[3]
lower_quartile <- bp$stats[2]
upper_quartile <- bp$stats[4]

cat("Median:", median_values, "\n")
cat("Lower Quartile (Q1):", lower_quartile, "\n")
cat("Mean Price (euros):", mean_price, "\n")
cat("Upper Quartile (Q3):", upper_quartile, "\n")

remove_outliers <- function(x, na.rm = TRUE, ...){
  qnt <- quantile(x, probs = c(.25, .75), na.rm=na.rm,...)
  H<- 1.5 *IQR(x, na.rm =na.rm)
  y<-x
  y[x< (qnt[1] -H)]<-NA
  y[x>qnt[2] +H]<- NA
  y
}
```

###4: data splitting and adding attributes


### Data Splitting

#### Data splitting on CPU

##### ##### CPU attribute is nominal and has 115 unique value, We could not use it until we categorized it into 10 values, we used the CPU brand and generation to categorize it. For "Intel Core i5" and "Intel Core i7", we noticed that they present more than 50% of the data, so we used the clock speed to categorize it further into CPUs with clock speed larger than 2 GHz or less. This step enabled us to generate usefull graphs out of this attribute.

##### You can notice from the graph that some CPU types can be described as low in price like "AMD A-Series", "AMD E-Series", "Intel Atom x", "Intel Celeron", "Intel Core i3", and "Intel Pentium". We can also see that "Intel Core i5", "Intel Core i7", and "Intel Core M" has a large range of value, it can be described as "Average" or "High" in price.
```{r}

dataset$price=cut (dataset$Price_euros, breaks=c(150, 400, 1250, 3200), labels=c("cheap","affordable","expensive"))
#Find unique values in CPU
unique(dataset$Cpu)
# categorizing CPU types
pattern_categories <- data.frame(
              Cpu = c("Intel Core i3 .*","Intel Core i5 .*", "Intel Core i7 .*", "Intel Core i9 .*",
                          "Intel Core M.*", "(?i)Intel Atom x.*",
                          "Intel Celeron .*","Intel Pentium .*",
                          "AMD A.*", "AMD E.*"),
              
                Category = c("Intel Core i3", "Intel Core i5", "Intel Core i7","Intel Core i9",
                             "Intel Core M", "Intel Atom x",
                             "Intel Celeron", "Intel Pentium", 
                             "AMD A-Series", "AMD E-Series")
  )

# Intel Atom X5-Z8350 1.44GHz was not categoried bc of X instead of x so I should correct it

# assigning categories based on patterns
assign_category <- function(Cpu) {
  for (i in 1:nrow(pattern_categories)) {
    if (grepl(pattern_categories$Cpu[i], Cpu)) {
      return(pattern_categories$Category[i])
    }
  }
  return("Other")  # if no patterns match, it assigns it to "Other"
}


#new column with categories
Cpu_Categories <- sapply(dataset$Cpu, assign_category)

#data frame with CPU names and categories
cpu_data <- data.frame(CPU_Name = dataset$Cpu, Category = Cpu_Categories)

# adding the category coloum to the dataset
dataset <- data.frame(ID = dataset$ID, Company = dataset$Company, Product = dataset$Product,
                  TypeName = dataset$TypeName, Inches = dataset$Inches, 
                  ScreenResolution = dataset$ScreenResolution, Cpu = dataset$Cpu,
                  Category = cpu_data$Category,Ram = dataset$Ram,
                  Memory = dataset$Memory, Gpu = dataset$Gpu, OpSys = dataset$OpSys, 
                  Weight = dataset$Weight, Price_euros = dataset$Price_euros
                  )

# Extract GHz from CPU names
dataset$categories <- as.numeric(gsub(".*?(\\d+\\.\\d+)GHz.*", "\\1", dataset$Cpu))

dataset$CategoryCPU <- dataset$Category

dataset$CategoryCPU <- ifelse(
  (dataset$Category == "Intel Core i7" | dataset$Category == "Intel Core i5") & dataset$categories <= 2,
  paste(dataset$Category, "<2", sep = " "), dataset$CategoryCPU
)

dataset$CategoryCPU <- ifelse(
  (dataset$Category == "Intel Core i7" | dataset$Category == "Intel Core i5") & dataset$categories > 2,
  paste(dataset$Category, ">2", sep = " "), dataset$CategoryCPU
)

dataset$Cpu<-NULL
dataset$categories<-NULL


# Plot dataset
ggplot(dataset, aes(x = CategoryCPU, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0) +
  labs(title = "Jitter Plot of Laptop Prices by CPU Type", x = "CPU Type", y = "Price (in Euros)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#### Data splitting on GPU
##### GPU attribute is nominal and has 103 unique value, We could not use it until we categorized it into 7 values, we used the GPU brand and generation to categorize it. This step enabled us to generate usefull graphs out of this attribute.

##### We can notice that "AMD Radeon Graphics" and "Intel UHD Graphics" is in the cheaper range. For "Intel HD Graphics" and "Nvidia GeForce Graphics" we see that thier price range is large, they can be categorized as "Average" or "High" in price. As for "Intel Iris Graphics" and "Nvidia GeForce Graphics", they range above 1250, we can describe them as "High" in price.
```{r}

# Categorizing GPU types
gpu_pattern_categories <- data.frame(
  Gpu = c("Intel Iris.*", "Intel HD Graphics.*", "AMD Radeon.*", "Nvidia GeForce.*", "Intel UHD Graphics.*", "Nvidia Quadro .*"),
  Category = c("Intel Iris Graphics", "Intel HD Graphics", "AMD Radeon Graphics", "Nvidia GeForce Graphics", "Intel UHD Graphics", "Nvidia Quadro")
)

# Function to assign GPU categories based on patterns
assign_gpu_category <- function(gpu_name) {
  for (i in 1:nrow(gpu_pattern_categories)) {
    if (grepl(gpu_pattern_categories$Gpu[i], gpu_name)) {
      return(gpu_pattern_categories$Category[i])
    }
  }
  return("Other")  # Assign to "Other" category if no patterns match
}


# Create a new column "Gpu_Category"
dataset$CategoryGPU <- sapply(dataset$Gpu, assign_gpu_category)
dataset$Gpu<-NULL

#plot
ggplot(dataset, aes(x = CategoryGPU, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0) +
  labs(title = "Jitter Plot of Laptop Prices by GPU Category", x = "GPU Category", y = "Price (in Euros)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

dataset <- dataset[, c("ID", "Company", "Product", "TypeName", "Inches", "ScreenResolution","CategoryCPU", "Ram", "Memory", "CategoryGPU", "OpSys", "Weight", "Price_euros")]

```

#### Data splitting on Memory
##### Since Memory attribute had more than one information, we split the Memory attribute into: Memory type, and memory size -where sizes unit is in GB- to show the effect of each information.

##### We can notice that "Flash Storage", "HDD", and "Hybrid" is in the cheaper range. "SSD has a large price range so it can be categorized as "Low", "Average" or "High".For "SSD&HDD" we see that its price range is large, it can be categorized as "Average" or "High".

##### Memory sizes that are (16,32,64)GB can be categorized as "Low". For (500,1000)GB it can be described as "Low" or "Average". For (256,1024,1128)GB it can be categorized as "Average" or "High". For (512,1256)GB it can be categorized as "High".

```{r}
# categorizing Memory types
dataset$Memory=factor(dataset$Memory,levels=c("128GB SSD" ,  "128GB Flash Storage" ,         
                                              "256GB SSD" ,                    "512GB SSD",                    
                                              "500GB HDD",                     "256GB Flash Storage" ,         
                                              "1TB HDD",                       "32GB Flash Storage"  ,         
                                              "128GB SSD +  1TB HDD",          "256GB SSD +  256GB SSD",       
                                              "64GB Flash Storage",            "256GB SSD +  1TB HDD",         
                                              "256GB SSD +  2TB HDD" ,         "32GB SSD",                     
                                              "2TB HDD",                       "64GB SSD",                     
                                              "1.0TB Hybrid",                  "512GB SSD +  1TB HDD",         
                                              "1TB SSD" ,                      "256GB SSD +  500GB HDD",       
                                              "128GB SSD +  2TB HDD",          "512GB SSD +  512GB SSD",       
                                              "16GB SSD",                      "16GB Flash Storage",           
                                              "512GB SSD +  256GB SSD" ,       "512GB SSD +  2TB HDD",         
                                              "64GB Flash Storage +  1TB HDD", "180GB SSD",                    
                                              "1TB HDD +  1TB HDD" ,           "32GB HDD",                     
                                              "1TB SSD +  1TB HDD" ,           "512GB Flash Storage",          
                                              "128GB HDD",                     "240GB SSD",                    
                                              "8GB SSD",                       "508GB Hybrid",                 
                                              "1.0TB HDD",                     "512GB SSD +  1.0TB Hybrid",    
                                              "256GB SSD +  1.0TB Hybrid"),
                   labels=c("128GB SSD" ,  "128GB Flash Storage" ,         
                            "256GB SSD" ,                    "512GB SSD",                    
                            "500GB HDD",                     "256GB Flash Storage" ,         
                            "1000GB HDD",                       "32GB Flash Storage"  ,         
                            "1128GB SSD&HDD",          "512GB SSD  SSD",       
                            "64GB Flash Storage",            "1256GB SSD&HDD",         
                            "2256GB SSD HDD" ,         "32GB SSD",                     
                            "2000GB HDD",                       "64GB SSD",                     
                            "1000GB Hybrid",                  "1512GB SSD&HDD",         
                            "1000GB SSD" ,                      "756GB SSD&HDD",       
                            "2128GB SSD&HDD",          "1024GB SSD",       
                            "16GB SSD",                      "16GB Flash Storage",           
                            "768GB SSD" ,       "2512GB SSD&HDD",         
                            "164GB Flash Storage HDD", "180GB SSD",                    
                            "2000GB HDD" ,           "32GB HDD",                     
                            "2000GB SSD&HDD" ,           "512GB Flash Storage",          
                            "128GB HDD",                     "240GB SSD",                    
                            "8GB SSD",                       "508GB Hybrid",                 
                            "1000GB HDD",                     "1512GB SSD&Hybrid",    
                            "1256GB SSD&Hybrid"))

#find the memory type and set it as an attribute
dataset$MemoryType <- gsub(".*GB", "", dataset$Memory)

#find the memory size and set it as an attribute
dataset$MemorySize <- gsub("GB.*", "", dataset$Memory)

#conver memory size to numeric 
dataset$MemorySize<- as.numeric(as.character(dataset$MemorySize))

# remove Memory attribute to reduce redundency
dataset$Memory<-NULL

# Plot dataset based on MemoryType
ggplot(dataset, aes(x = MemoryType, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0) +
  labs(title = "Jitter Plot of Laptop Prices by Memory Type", x = "Memory Type", y = "Price (in Euros)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plotting for the "MemorySize" variable
ggplot(dataset, aes(x = MemorySize, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0) +
  labs(title = "Jitter Plot of Laptop Prices by Memory Size", x = "Memory Size", y = "Price (in Euros)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


####5: correlation& covariance analysis

#### Covariance 
##### Covariance measures the relationship between two variables. A positive covariance suggests that the variables tend to increase together, while a negative covariance suggests that one variable increases as the other decreases. However, it doesn't provide the strength or direction of the relationship.
```{r}
#Covariance of Price_euros and Weight
cov(dataset$Price_euros,dataset$Weight)

#Covariance of Price_euros and Inches
cov(dataset$Price_euros,dataset$Inches)
```

#### Calculating the variance for numeric data

##### The variance is 399382.9, the variance for laptop prices reveals significant variations among different Company, operation system , and Ram size,etc.
```{r}
#variance of Price_euros
var(dataset$Price_euros)
```


##### The variance is 0.4207763,The low variance in laptop weights indicates consistent weight patterns across various models.
```{r}
#variance of Weight
var(dataset$Weight)
```


##### The variance is 2.015324,A low variance in laptop screen sizes suggests a standardized trend among models. 
```{r}
#variance of Inches 
var(dataset$Inches)
```


#### Standard Deviation of numeric data


##### The standard deviation is 631.9674. The high standard deviation of laptop prices reveals the extent of price dispersion from the mean. A higher standard deviation signifies a wider price range, indicating more significant price variations. 
```{r}
#standard deviation of laptop prices 
sd(dataset$Price_euros)
```


##### The standard deviation is 0.6486727. A low standard deviation in laptop weights implies a minimal deviation from the mean weight, showcasing consistency in manufacturing.
```{r}
#standard deviation of weight
sd(dataset$Weight)
```


##### The standard deviation is 1.419621 . A low standard deviation in laptop screen sizes indicates a narrow range of variation around the mean,providing consumers with a predictable and standard selection of laptop displays across different models and brands.
```{r}
#standard deviation of screen size in inches 
sd(dataset$Inches)
```


##### Relationship between price of laptop and company
```{r}
ggplot(dataset,aes(Price_euros,Company))+geom_point()
```


##### Relationship between price of laptop and operating system
```{r}
ggplot(dataset,aes(Price_euros,OpSys))+geom_point()
```


##### Relationship between price of laptop and type of laptop
```{r}
ggplot(dataset,aes(Price_euros,TypeName))+geom_point()
```


##### Relationship between price of laptop and Ram
```{r}
ggplot(dataset,aes(Price_euros,Ram))+geom_point()
```




### Statstical Summaries

##### This function provides insights into the central tendency of the data through measures like mean and median. offering a sense of the dataâ€™s central location.you can notice the mean of the Price_euros is 1095.4,for the Inches it is 15,for the Weight its 2.025 ,the median for the Price_euros is 961.0  ,the median for the weight is 2.040  ,the median for the Inches is 15.6 The summary includes information about the spread of the data, providing the minimum and maximum values. This gives a sense of the range within which the data is distributed,for the Price_euros the range is between 174 and 3154 ,for the Weight it is between 0.690 and 4.600,for the Inches it is between 10.1 and 18.4.

##### The summary function provides quartiles, which, when combined with the median, help identify skewness or asymmetry in the data distribution.

##### For the Price_euros column the  Q1 < Q2 < Q3 it indicates it is  right-skewed (positively skewed) distribution.
##### For the weight column the  Q1 < Q2 < Q3 it indicates it is  right-skewed (positively skewed) distribution.
##### For the inches column the  Q1 < Q2 < Q3 it indicates it is  right-skewed (positively skewed) distribution.


```{r}
summary(dataset)
```

#### Find the mean of all data


##### Based on my observation of the dataset, the mean of the prices of laptops is 1095.413. Analyzing this can help consumers understand the overall pricing trend and make informed decisions based on their budget.
```{r}
#mean of laptop prices .
mean(dataset$Price_euros)
```


##### Based on my observation of the dataset, the mean of the laptop screen sizes measured in inches is 15.00116. Analyzing this can help consumers choose a suitable laptop based on their preferences for display dimensions and portability.
```{r}
#mean of laptop screen sizes in inches .
 
mean(dataset$Inches)
```


##### Based on my observation of the dataset, the mean of the weight of laptops is 2.025469 . interpreting this allows users to grasp the typical weight of available laptops, aiding consumers in choosing portable or robust device based on their needs.
```{r}
#mean of laptop weights .
mean(dataset$Weight)
```


#### Find median of all data


##### The median is 961,The median laptop price represents the middle point, offering a central value that helps consumers understand a typical price range.
```{r}
#median of laptop prices
median(dataset$Price_euros)
```


##### The median is "HP",The median of laptop companies signifies the middle point, providing insight into the industry's typical market positioning and competitiveness.
```{r}
#median of Company
median(dataset$Company)
```


##### "Legion Y520-15IKBN"   The median of laptop brands suggests the midpoint, aiding consumers in identifying a typical brand positioning within the market.
```{r}
#median of Product
median(dataset$Product)
```


##### "Notebook"  The median of laptop types reveals the midpoint, illustrating a typical classification representing consumer preferences and market distribution.
```{r}
#median of TypeName
median(dataset$TypeName)
```


##### 15.6  The median of laptop screen sizes offers a central point, aiding in understanding the typical display size available.
```{r}
#median of Inches
median(dataset$Inches)
```


##### "Full HD 1920x1080" The median of screen resolutions indicates a central value, reflecting a typical display quality preferred by laptop users.
```{r}
#median of Screen Resolution
median(dataset$ScreenResolution)
```


##### "Intel Core i5 >2" The median of CPU (central processing unit) signifies a central performance level, representing a typical processing power preferred by users.
```{r}
#median of Cpu
median(dataset$CategoryCPU) 
```


##### 2.04  The median of laptop weights gives a central weight value, aiding in identifying a typical weight range for laptops.
```{r}
#median of Weight
median(dataset$Weight)
```


##### "3"  which is decoded as windows 10  The median of operating systems reflects the midpoint, showing a typical OS preference and market distribution for laptop users.
```{r}

#median of OpSys
median(dataset$OpSys)
```


##### "8"  The median of RAM size provides a central value, offering insight into the common memory capacity preferred by laptop users.
```{r}
#median of Ram
median(dataset$Ram)
```


##### "Intel HD Graphics" The median of GPU (graphics processing unit) denotes a central value, showcasing a typical level of graphics performance preferred by users.
```{r}
#median of Gpu Category
median(dataset$CategoryGPU)
```


##### "256" The median of memory capacity showcases a central value, offering insight into a typical storage preference among laptop users.
```{r}
#median of Memory
median(dataset$MemorySize)
```

##### "SSD" The median of memory type showcases a central value, offering insight into a typical Type preference among laptop users.
```{r}
#median of Memory
median(dataset$MemoryType)
```

#### Mode of data 


##### The mode is 2.2, it is the most common weight range in the market, revealing preferences and trends influencing consumer choices.
```{r}
Data_Set <- dataset
#mode of weight
names(sort(-table(Data_Set$Weight)))[1]
```


##### The mode is 1099,it indicates the most frequently occurring price range, providing insight into the market's preferred price points and consumer purchasing patterns.
```{r}
#mode of price
names(sort(-table(Data_Set$Price_euros)))[1]
```


##### The mode is 15.6, it reveals the most prevalent screen dimensions.
```{r}
#mode of screen size in inches
names(sort(-table(Data_Set$Inches)))[1]
```


##### The mode is "Dell", it highlights the most dominant brand.
```{r}
#mode of company
names(sort(-table(Data_Set$Company)))[1]
```


##### The mode is "XPS 13", it highlights the most dominant product.
```{r}
#mode of product
names(sort(-table(Data_Set$Product)))[1]
```


##### The mode is "Intel Core i7 >2 ", it reveals the most prevalent processors.
```{r}
#mode of cpu
names(sort(-table(Data_Set$CategoryCPU)))[1]
```


##### The mode is "8", it identifies the most common memory capacity.
```{r}
#mode of ram
names(sort(-table(Data_Set$Ram)))[1]
```


##### The mode is  3 which is decoded as Windows 10, it highlights the most dominant opertion system.
```{r}
#mode of operating system
names(sort(-table(Data_Set$OpSys)))[1]
```



#### Find the range for all data

##### the lowest price of laptop is  174, and the highest price is 3154 so the range equals (3154-174=2980). The range suggests diverse pricing options, catering to varying budgets . 
```{r}
#range of laptop prices .
range(dataset$Price_euros)
```


##### the lowest of weight laptop is  0.69, and the highest weight is 4.60. the range suggests a diverse array of laptop weights, understanding this range aids consumers in selecting a laptop that aligns with their mobility needs considering factors like portability and ease of use.
```{r}
#range of laptop weights . 
range(dataset$Weight)
```


##### the lowest oflaptop screen size is 10.1,and the highest is  18.4. so whether you prefer a compact and portable laptop or a larger screen ,there is plenty of options available within the range.
```{r}
#range of laptop screen sizes in inches .
range(dataset$Inches)
```






#### Finding the number of attributes, Observation, strucutre, statistical measures, etc..
```{r}
nrow(dataset)
ncol(dataset)
dim(dataset)
names(dataset)
str(dataset)
is.null(dataset)

```

















### Graphs

#### Product Histogram
##### Top 5 bought laptops are: XPS 13, EliteBook 840, IdeaPad Y700-15ISK, IdeaPad 320-15IAP, Blade Pro.
```{r}

#---
productHist <- table(dataset$Product)
productHist <- productHist[order(-productHist)]
barplot(productHist, main = "Frequency of Product", 
        ylab = "Frequency",
        las = 2,cex.names = 0.6)
```


#### Memory Sizes Histogram
##### Top 3 types of Memory Sizes are: 256GB, 1000GB, 500GB.
```{r}
#---
memorySizeHist <- table(dataset$MemorySize)
memorySizeHist <- memorySizeHist[order(-memorySizeHist)]
barplot(memorySizeHist, 
        main = "Frequency of Memory Size",
        ylab = "Frequency",
        las = 2, cex.names = 0.6)
```

#### Treemap

##### We used treemaps instead of pie chart to represent nominal data since most of our attributes have too many items. Pie chart would overlap our labels.

##### We can see all companies with thier details. "Dell" and "Lenovo" has equal percentage.
```{r}
# Calculate the frequency of each company
company_counts <- table(dataset$Company)
company_freq <- data.frame(Company = names(company_counts), Frequency = as.numeric(company_counts))
company_freq <- company_freq[order(company_freq$Frequency, decreasing = TRUE), ]
# Create a treemap
treemap <- plot_ly(
  company_freq,
  labels = ~Company,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap <- treemap %>%
  layout(title = "Company Frequency Treemap")
# print Company Treemap
treemap

```

##### We can see that around 50% of the laptops are "Notebook".
```{r}

# Calculate the frequency of each TypeName
type_counts <- table(dataset$TypeName)
type_freq <- data.frame(TypeName = names(type_counts), Frequency = as.numeric(type_counts))
type_freq <- type_freq[order(type_freq$Frequency, decreasing = TRUE), ]
# Create a treemap
treemap <- plot_ly(
  type_freq,
  labels = ~TypeName,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap <- treemap %>%
  layout(title = "TypeName Frequency Treemap")
# print TypeName Treemap
treemap
```

##### we can see that around 50% of the Ram are "8".
```{r}
# Calculate the frequency of each RAM category
ram_counts <- table(dataset$Ram)
ram_freq <- data.frame(Ram = names(ram_counts), Frequency = as.numeric(ram_counts))
ram_freq <- ram_freq[order(ram_freq$Frequency, decreasing = TRUE), ]
# Create a treemap
treemap <- plot_ly(
  ram_freq,
  labels = ~Ram,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap <- treemap %>%
  layout(title = "RAM Frequency Treemap")
# print Ram Treemap
treemap
```

##### we can see that Intel Core i7 >2, Intel Core i5 >2 take over 50% of the CPU.
```{r}
# Calculate the frequency of each CPU category
cpu_counts <- table(dataset$CategoryCPU)
cpu_freq <- data.frame(CategoryCPU = names(cpu_counts), Frequency = as.numeric(cpu_counts))
cpu_freq <- cpu_freq[order(cpu_freq$Frequency, decreasing = TRUE), ]
# Create a treemap
treemap_cpu <- plot_ly(
  cpu_freq,
  labels = ~CategoryCPU,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap_cpu <- treemap_cpu %>%
  layout(title = "CPU Category Frequency Treemap")
# Print CPU Treemap
treemap_cpu
```

##### Top 2 types of GPUs are: Intel HD Graphics is double the amount Nvidia GeForce Graphics. Both of them represent around 75% of the data.
```{r}
# Calculate the frequency of each GPU category
gpu_counts <- table(dataset$CategoryGPU)
gpu_freq <- data.frame(CategoryGPU = names(gpu_counts), Frequency = as.numeric(gpu_counts))
gpu_freq <- gpu_freq[order(gpu_freq$Frequency, decreasing = TRUE), ]

# Create a treemap
treemap_gpu <- plot_ly(
  gpu_freq,
  labels = ~CategoryGPU,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap_gpu <- treemap_gpu %>%
  layout(title = "GPU Category Frequency Treemap")
  
# Print GPU Category Treemap
treemap_gpu
```

##### We can see the Windows 10 system is over 75% .
```{r}
# Calculate the frequency of each OpSys
opsys_counts <- table(dataset$OpSys)
opsys_freq <- data.frame(OpSys = names(opsys_counts), Frequency = as.numeric(opsys_counts))
opsys_freq <- opsys_freq[order(opsys_freq$Frequency, decreasing = TRUE), ]
# Create a treemap for OpSys
treemap_opsys <- plot_ly(
  opsys_freq,
  labels = ~OpSys,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap_opsys <- treemap_opsys %>%
  layout(title = "OpSys Frequency Treemap")
# print OpSys Treemap
treemap_opsys
```


#### Bar chart

#### Company Bar chart and Histogram
##### Top 5 frequent companies were Dell, Lenovo, HP, Asus, Acer. For Dell, Lenovo, HP, Asus, we can notice that thier price is average, which explains that their affordable prices is why it was from the seller companies. For Acer, it is around low in price, so its cheap price, made it preferable to people.
```{r}


#Company histogram
companyHist <- table(dataset$Company)
companyHist <- companyHist[order(-companyHist)]
barplot(companyHist, main = "Frequency of Company", 
        ylab = "Frequency",
        las = 2,cex.names = 0.8)

#Company Bar chart
dataset %>%
  group_by(Company) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(Company, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by Company", x = "Company", y = "Average Price for each company") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#### Ram Bar chart, jitter plot, and Histogram
##### Top 3 bought types of RAM are: 8,4,16 we can notice from the 3 graphs that 8 is considered average in price, 4GB is considered Low in price, 16GB is considered High in price. This variety explains the difference of costumers preferances.

```{r}

#---------------
ramHist <- table(dataset$Ram)
ramHist <- ramHist[order(-ramHist)]
barplot(ramHist, main = "Frequency of RAM", 
        ylab = "Frequency",
        las = 2,cex.names = 0.8)
#---------------

# ram
dataset %>%
  group_by(Ram) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(Ram, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by RAM", x = "RAM", y = "Average Price for each RAM type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
#---------------
  ggplot(dataset, aes(x = Ram, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0, alpha = 0.5) +
  labs(title = "Jitter Plot of Price (in Euros) vs. RAM", x = "RAM", y = "Price (in Euros)") +
  theme_minimal()

```
#### Laptops types bar chart and Histogram

##### Top 3 boyght types of laptops are: Notebook, Gaming, Ultrabook. Notebook and Ultrabook which are the most bought type is considered average in price, and for gaming it is considered high in price.

```{r}

#---
typeHist <- table(dataset$TypeName)
typeHist <- typeHist[order(-typeHist)]
barplot(typeHist, main = "Frequency of Type", 
        ylab = "Frequency",
        las = 2,cex.names = 0.6)


# typeName
dataset %>%
  group_by(TypeName) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(TypeName, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by TypeName", x = "TypeName", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

#### Operating system bar chart and Histogram

##### Top 3 types of Operating Systems are: Windows 10, No OS, Linux. Windows 10 is considered average in price, this is explains why it is the top seller Operating system. No OS and Linux. can be described as cheap since they have average price.
```{r}
# opSys
opSysHist <- table(dataset$OpSys)
opSysHist <- opSysHist[order(-opSysHist)]
barplot(opSysHist, main = "Frequency of Operating Systems", 
        ylab = "Frequency",
        las = 2,cex.names = 0.8)
#---
dataset %>%
  group_by(OpSys) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(OpSys, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by Operating system", x = "Operating System", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
#### CPU Category bar chart and Histogram

##### Top 3 types of CPUs are: Intel Core i7 >2, Intel Core i5 >2, Intel Core i3. From our results from the Jitter plot we can see that "Intel Core i3" can be described as "cheap", this explains why it was from the top 3 sellers. For "Intel Core i7 >2" and "Intel Core i5 >2" they had a large range, and represent more than 50% of the dataset, this explains why it was from the top 3.
##### "Intel Core i3" is considered low in price, this eplains why these two are from the top sellers. For "Intel Core i5 >2" it has average price.. We can see that "Intel Core i7 >2" average price is high, but we can not categorize it as high in price, since it takes around 30% of the data, and has a large range of values.

```{r}
#CategoryCPU

#---
cpuHist <- table(dataset$CategoryCPU)
cpuHist <- cpuHist[order(-cpuHist)]
barplot(cpuHist, main = "Frequency of CPU", 
        ylab = "Frequency",
        las = 2,cex.names = 0.6)


dataset %>%
  group_by(CategoryCPU) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(CategoryCPU, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by CPU Category", x = "CPU Category", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#### GPU Category bar chart and Histogram

##### "Intel HD Graphics" and "Nvidia GeForce Graphics" they had a large range in the jitter plot, so it has multible price options for customers. we can also see that "AMD Radeon Graphics" which we described as average price is from the top 3 sellers.
```{r}

#---
gpuHist <- table(dataset$CategoryGPU)
gpuHist <- gpuHist[order(-gpuHist)]
barplot(gpuHist, main = "Frequency of GPU", 
        ylab = "Frequency",
        las = 2,cex.names = 0.6)

#CategoryGPU
dataset %>%
  group_by(CategoryGPU) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(CategoryGPU, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by GPU Category", x = "GPU Category", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```
#### Memory Type bar chart and Histogram

##### Top 3 types of Memory Types are: SSD, HDD, SSD&HDD. SSD had a large range of values in the jitter plot, it offer a large variety of options, this explains why it is the most frequent product. "HDD" was in the cheaper range this is why it is the second most frequent product. For "HDD&SSD" it was categoreized as average price or high in price, so it was the 3rd frequent product.
```{r}

#-------------------
memoryTypeHist <- table(dataset$MemoryType)
memoryTypeHist <- memoryTypeHist[order(-memoryTypeHist)]
barplot(memoryTypeHist, main = "Frequency of Memory Type",
        ylab = "Frequency",
        las = 2, cex.names = 0.6)
#------------------

dataset %>%
  group_by(MemoryType) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(MemoryType, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by Memory Type", x = "Memory Type", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Normalization 

##### The price_euros, inches, weight attributes has a huge values we normalized it and scaled it to be between the values 0 and 1, And by taking this step it will help with handling and analyzing so that it would be understandable.
```{r}
 #Normalization 
  normalize = function(x) {return ((x-min(x)) / (max(x)))} 
  dataset$Price_euros = normalize(dataset$Price_euros)
  dataset$Inches = normalize(dataset$Inches)
  dataset$Weight = normalize(dataset$Weight)
```

### Feature Selection
##### we have the chi square for the nominal attributes and we choose the classes[cpuCategory,Resulotion,MemoryType]

##### according to chi square we figure that there is a high positive relationship between the class lable[price] and CpuCategory which can be a result of Cpus' powerful impact, therfore Cpu's with higher performance and advanced technology tend to be more expensive.  

##### according to chi square we figure that there is a high positive relationship between the class lable[price] and Resulotion since laptops with higher resolutions have a detailed display which can enhance the visual experience and this tend to make the price higher due to the cost of manufacturing and the improved viewing experience they offer.

##### according to chi square we figure that there is a high positive relationship between the class lable[price] and Memory and that's because a higher memory allows for better multitasking, faster performance, and more storage space for files and applications which have a huge impact on the price of a laptop.

##### for the other attributes which are OpySys, Type Name, and company all of them have an effect on the price but not as important as the prevoius attributes.  



##### the correlation for the numeric attributes and we have Ram,Weight,Inches,MemorySize.  
. 
##### Ram has a huge impact on the price since it provides smoother multitasking so laptops with larger ram have a higher price. 
##### for the Weight and Inches it has an effect on the price but not as much as the Ram , since Weight and Inches have a less correlation with the class lable[price] than Ram and because they don't offer a new or enhanced features but generally smaller and lighter are more portable and convenient which can make them more expensive, on the other hand heavier laptops may have more room for additional components and features such as a bigger Ram and more memory space which can also increase the price since the Ram and memorySize correlated positively.So, the Weight and Inches might play a role in determining the price of a laptop.

##### we don't have any redundant variables so, we didn't need to remove any attribute.
```{r}
# Feature selection
result=chisq.test(dataset$Price_euros , dataset$Company)
print(result)
result=chisq.test(dataset$Price_euros , dataset$Product)
print(result)
result=chisq.test(dataset$Price_euros , dataset$TypeName)
print(result)
result=chisq.test(dataset$Price_euros , dataset$ScreenResolution)
print(result)
result=chisq.test(dataset$Price_euros , dataset$cpuCategory)
print(result)
result=chisq.test(dataset$Price_euros , dataset$MemoryType)
print(result)
result=chisq.test(dataset$Price_euros , dataset$OpSys)
print(result)
result=chisq.test(dataset$Price_euros , dataset$gpuCategory)
print(result)


result2=cor(dataset$Price_euros ,dataset$Inches)
print(result2)
result2=cor(dataset$Price_euros ,dataset$Ram)
print(result2)
result2=cor(dataset$Price_euros ,dataset$Weight)
print(result2)
result2=cor(dataset$Price_euros ,dataset$MemorySize)
print(result2)

```

